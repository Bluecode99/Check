{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGPlYumZnO1t"
      },
      "source": [
        "# Simple Neural Network using Keras\n",
        "\n",
        "\n",
        "## Introduction\n",
        "Our use case is to build, train, and evaluate a prediction model for sales analysis.\n",
        "\n",
        "In this model, we need to feed the advertising budget of TV, radio, and newspapers to the model and the model will forecast the possible sales.\n",
        "\n",
        "## Dataset\n",
        "The advertising dataset captures the sales revenue generated with respect to advertisement costs across numerous platforms like radio, TV, and newspapers.\n",
        "\n",
        "### Features:\n",
        "\n",
        "#### Digital: advertising dollars spent on Internet.\n",
        "#### TV: advertising dollars spent on TV.\n",
        "#### Radio: advertising dollars spent on Radio.\n",
        "#### Newspaper: advertising dollars spent on Newspaper.\n",
        "\n",
        "### Target (Label):\n",
        "#### Sales budget"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBXAUbijjNBF"
      },
      "source": [
        "# Step 1: Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsHg6SD2nO1v"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEXV-RxPnO1w"
      },
      "outputs": [],
      "source": [
        "# Import the necessary libraries\n",
        "\n",
        "# For Data loading, Exploratory Data Analysis, Graphing\n",
        "import pandas as pd   # Pandas for data processing libraries\n",
        "import numpy as np    # Numpy for mathematical functions\n",
        "\n",
        "import matplotlib.pyplot as plt # Matplotlib for visualization tasks\n",
        "import seaborn as sns # Seaborn for data visualization library based on matplotlib.\n",
        "%matplotlib inline\n",
        "\n",
        "import sklearn        # ML tasks\n",
        "from sklearn.model_selection import train_test_split # Split the dataset\n",
        "from sklearn.metrics import mean_squared_error  # Calculate Mean Squared Error\n",
        "\n",
        "# Build the Network\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "#from tensorflow.keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "\n",
        "#from keras.callbacks import EarlyStopping\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSDtqpd-Dk9H"
      },
      "outputs": [],
      "source": [
        "# Next, you read the dataset into a Pandas dataframe.\n",
        "\n",
        "url = 'https://github.com/LinkedInLearning/artificial-intelligence-foundations-neural-networks-4381282/blob/main/Advertising_2023.csv?raw=true'\n",
        "advertising_df= pd.read_csv(url,index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "Ue_jPccWnT30",
        "outputId": "70f4b09a-14b7-4d90-b4fc-1d9731ac527a"
      },
      "outputs": [],
      "source": [
        "advertising_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coiKjFmcnaHU",
        "outputId": "8501c8e5-3ced-45eb-afa7-46c697d3185c"
      },
      "outputs": [],
      "source": [
        "# Pandas info()Â function is used to get a concise summary of the dataframe.\n",
        "advertising_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "BTNIhkVYv9HZ",
        "outputId": "58b9a38d-7a2d-475c-81a6-dae736302621"
      },
      "outputs": [],
      "source": [
        "### Get summary of statistics of the data\n",
        "advertising_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzyfOhGaEzlL",
        "outputId": "a4a882d9-5740-4b8f-c8ef-8a1feac902df"
      },
      "outputs": [],
      "source": [
        "#shape of dataframe - 1199 rows, five columns\n",
        "advertising_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nNrSEBnBk71"
      },
      "source": [
        "Let's check for any null values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7gHdfMdBk71",
        "outputId": "58cd17b2-5760-4c4d-c8a0-2a56fc080e21"
      },
      "outputs": [],
      "source": [
        "# The isnull() method is used to check and manage NULL values in a data frame.\n",
        "advertising_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGbU2YpwFBIC",
        "outputId": "f2bea7ec-3bcf-4fce-a20c-7f8fc55ee802"
      },
      "outputs": [],
      "source": [
        "#check there are any NAN values\n",
        "advertising_df.isnull().values.any()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWVdsrmgnO1_"
      },
      "source": [
        "## Exploratory Data Analysis (EDA)\n",
        "\n",
        "Let's create some simple plots to check out the data!  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "qqsAMR1rov7F",
        "outputId": "b93dc775-49dc-4d17-e30a-e7d842e8b3bf"
      },
      "outputs": [],
      "source": [
        "# The heatmap is a way of representing the data in a 2-dimensional form. The data values are represented as colors in the graph.\n",
        "# The goal of the heatmap is to provide a colored visual summary of information.\n",
        "sns.heatmap(advertising_df.corr())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "i8bsyyVPm13-",
        "outputId": "08b9e815-6937-4d2e-dc5d-c3db9cf77d28"
      },
      "outputs": [],
      "source": [
        "## Another option is to plot the heatmap so that the values are shown.\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.heatmap(advertising_df.corr(),annot=True,vmin=0,vmax=1,cmap='ocean')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "8UdKVi-2tNKI",
        "outputId": "530307ee-f17f-4bd3-f6ce-67a3690f273c"
      },
      "outputs": [],
      "source": [
        "#create a correlation matrix\n",
        "corr = advertising_df.corr()\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.heatmap(corr[(corr >= 0.5) | (corr <= -0.7)],\n",
        "            cmap='viridis', vmax=1.0, vmin=-1.0, linewidths=0.1,\n",
        "            annot=True, annot_kws={\"size\": 8}, square=True)\n",
        "plt.tight_layout()\n",
        "display(plt.show())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "dNlslaNtuO2Q",
        "outputId": "f8417a52-c743-41eb-c4aa-02d093abeda9"
      },
      "outputs": [],
      "source": [
        "advertising_df.corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 842
        },
        "id": "WKFX9SCauZp4",
        "outputId": "64de2ac5-4703-428f-a738-454b72adb51e"
      },
      "outputs": [],
      "source": [
        "### Visualize Correlation\n",
        "\n",
        "# Generate a mask for the upper triangle\n",
        "mask = np.zeros_like(advertising_df.corr(), dtype=bool)\n",
        "mask[np.triu_indices_from(mask)] = True\n",
        "\n",
        "# Set up the matplotlib figure\n",
        "f, ax = plt.subplots(figsize=(11, 9))\n",
        "\n",
        "# Generate a custom diverging colormap\n",
        "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
        "\n",
        "# Draw the heatmap with the mask and correct aspect ratio\n",
        "sns.heatmap(advertising_df.corr(), mask=mask, cmap=cmap, vmax=.9, square=True, linewidths=.5, ax=ax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eDQ9CNw3uej"
      },
      "source": [
        "Since Sales is our target variable, we should identify which variable correlates the most with Sales.\n",
        "\n",
        "As we can see, TV has the highest correlation with Sales.\n",
        "Let's visualize the relationship of variables using scatterplots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "SOsTLClWnO2B",
        "outputId": "a734e4e1-4d91-4f3a-bd44-5ae4df3815b1"
      },
      "outputs": [],
      "source": [
        "# It is used basically for univariant set of observations and visualizes it through a histogram i.e. only one observation\n",
        "# and hence you choose one particular column of the dataset.\n",
        "sns.displot(advertising_df['sales'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ajx0zjPt4DIa"
      },
      "source": [
        "Let's visualize the relationship of variables using scatterplots. -- Separately"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f7bN--N5TYF"
      },
      "source": [
        "Another way to view the linear relationships between variables is to use a \"for loop\" that does the same as above.\n",
        "\n",
        "It seems there's no clear linear relationships between the predictors.\n",
        "\n",
        "At this point, we know that the variable TV will more likely give better prediction of Sales because of the high correlation and linearity of the two."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "id": "otYqhhMapHhY",
        "outputId": "bb3439aa-0e92-4ec9-dfb8-c2702aeb141d"
      },
      "outputs": [],
      "source": [
        "'''=== Show the linear relationship between features  and sales Thus, it provides that how the scattered\n",
        "      they are and which features has more impact in prediction of house price. ==='''\n",
        "\n",
        "# visualize all variables  with sales\n",
        "from scipy import stats\n",
        "#creates figure\n",
        "plt.figure(figsize=(18, 18))\n",
        "\n",
        "for i, col in enumerate(advertising_df.columns[0:13]): #iterates over all columns except for price column (last one)\n",
        "    plt.subplot(5, 3, i+1) # each row three figure\n",
        "    x = advertising_df[col] #x-axis\n",
        "    y = advertising_df['sales'] #y-axis\n",
        "    plt.plot(x, y, 'o')\n",
        "\n",
        "    # Create regression line\n",
        "    plt.plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1)) (np.unique(x)), color='red')\n",
        "    plt.xlabel(col) # x-label\n",
        "    plt.ylabel('sales') # y-label\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThNRxdAmA5fQ"
      },
      "source": [
        "Concluding results after observing the Graph\n",
        "The relation bw TV and Sales is strong and increases in linear fashion\n",
        "The relation bw Radio and Sales is less strong\n",
        "The relation bw TV and Sales is weak"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIPKB4hanO2F"
      },
      "source": [
        "## Training a Linear Regression Model\n",
        "\n",
        "Regression is a supervised machine learning process.  It is similar to classification, but rather than predicting a label, you try to predict a continuous value.   Linear regression defines the relationship between a target variable (y) and a set of predictive features (x).  Simply stated, If you need to predict a number, then use regression.\n",
        "\n",
        "Let's now begin to train your regression model! You will need to first split up your data into an X array that contains the features to train on, and a y array with the target variable, in this case the Price column. You will toss out the Address column because it only has text info that the linear regression model can't use."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFDhhs1KA22t"
      },
      "source": [
        "#### Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0NjRPeFBk74"
      },
      "source": [
        "##### Split: X (features) and y (target)\n",
        "Next, let's define the features and label.  Briefly, feature is input; label is output. This applies to both classification and regression problems."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEEGuBAnnO2F"
      },
      "outputs": [],
      "source": [
        "X = advertising_df[['digital', 'TV', 'radio', 'newspaper']]\n",
        "y = advertising_df['sales']\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXgBbCFcBCfG"
      },
      "source": [
        "##### Scaling (Normalization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVOPQyd2HtxP",
        "outputId": "29307080-cd33-406f-e5c6-c2b2c499ccd3"
      },
      "outputs": [],
      "source": [
        "'''=== Normalization the features. Since it is seen that features have different ranges, it is best practice to\n",
        "normalize/standardize the feature before using them in the model ==='''\n",
        "\n",
        "#feature normalization\n",
        "normalized_feature =  keras.utils.normalize(X.values)\n",
        "print(normalized_feature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X97FWdDOnO2H"
      },
      "source": [
        "##### Train - Test - Split\n",
        "\n",
        "Now let's split the data into a training and test set.  Note:  Best practices is to split into three - training, validation, and test set.\n",
        "\n",
        "By default - It splits the given data into 75-25 ration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fS99Llq8nO2J"
      },
      "outputs": [],
      "source": [
        "# Import train_test_split function from sklearn.model_selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split up the data into a training set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=101)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4p_3UGEcqPb",
        "outputId": "3b78c906-bae0-4d7d-9c06-7c62ef11bd38"
      },
      "outputs": [],
      "source": [
        "print(X_train.shape,X_test.shape, y_train.shape, y_test.shape )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdc8pL4TIb9k"
      },
      "source": [
        "# Step 2:  Build Network\n",
        "Because so few samples are available, we will be using a very small network with two hidden layers, each with 64 units. In general, the less training data you have, the worse overfitting will be, and using a small network is one way to mitigate overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J10hkM7BAhbh"
      },
      "source": [
        "#### Build and Train the Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-_Vage0th27",
        "outputId": "00f5710f-4b1c-45f7-d0b2-e45ba47759f5"
      },
      "outputs": [],
      "source": [
        "## Build Model (Building a three layer network - with one hidden layer)\n",
        "model = Sequential()\n",
        "model.add(Dense(4,input_dim=4, activation='relu'))                                                  # You don't have to specify input size.Just define the hidden layers\n",
        "model.add(Dense(3,activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Compile Model\n",
        "model.compile(optimizer='adam', loss='mse',metrics=['mse'])\n",
        "\n",
        "#  Fit the Model\n",
        "history = model.fit(X_train, y_train, validation_data = (X_test, y_test),\n",
        "                    epochs = 32)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZ_b0LGtE0By"
      },
      "source": [
        "#### Model Summary\n",
        "Once we've run data through the model, we can call .summary() on the model to get a high-level summary of our network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0u5rBxABCtw7",
        "outputId": "57e05bec-cea9-49fc-9b8d-490edbac79e7"
      },
      "outputs": [],
      "source": [
        "#inspect the model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLoJRfUtn27m",
        "outputId": "693b7de0-cd5b-46f9-b375-b887fd37937d"
      },
      "outputs": [],
      "source": [
        "model.evaluate(X_test, y_test)[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHBzoonKnFfj"
      },
      "source": [
        "### Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5_YlrlTFc92"
      },
      "source": [
        "Running .fit (or .fit_generator) returns a History object which collects all the events recorded during training. You can plot the training and validation curves for the model loss and mse by accessing these elements of the History object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "D0q6HDS_FMx-",
        "outputId": "ff295d84-2cc3-4258-cc48-7a5ff9dc4b74"
      },
      "outputs": [],
      "source": [
        "MSE_COLS = [\"mse\", \"val_mse\"]\n",
        "\n",
        "pd.DataFrame(history.history)[MSE_COLS].plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktMqgjoDGAe7"
      },
      "source": [
        "You can add more 'flavor' to the graph by making it bigger and adding labels and names, as shown below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "jB1VUt-bmTPH",
        "outputId": "ffcb6a85-79d8-4008-bfba-7660bb9a4f58"
      },
      "outputs": [],
      "source": [
        "## Plot a graph of model loss # show the graph of model loss in training and validation\n",
        "\n",
        "plt.figure(figsize=(15,8))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss (MSE) on Training and Validation Data')\n",
        "plt.ylabel('Loss-Mean Squared Error')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Val Loss', 'Train Loss'], loc='upper right')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CD54f4wCIik2"
      },
      "source": [
        "### Predict Sales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p75QVFqwBwmk",
        "outputId": "731bd68a-e49b-4b88-c716-a0f802669e9b"
      },
      "outputs": [],
      "source": [
        "'''=== predict the SALES =='''\n",
        "\n",
        "# predict SALES using the test data\n",
        "test_predictions = model.predict(X_test).flatten()\n",
        "print(test_predictions)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-o7RZMLAImvP"
      },
      "source": [
        "### True and Predicted Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "if37LiYZCbD0",
        "outputId": "363defea-91b5-4ba5-9670-8ea312e80ad2"
      },
      "outputs": [],
      "source": [
        "# show the true value and predicted value in dataframe\n",
        "true_predicted = pd.DataFrame(list(zip(y_test, test_predictions)),\n",
        "                    columns=['True Value','Predicted Value'])\n",
        "true_predicted.head(6) # Show first six rows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CPfIujVIuUf"
      },
      "source": [
        "Visualize the prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "XgkvEWW-BRJF",
        "outputId": "0689ad4d-3a2e-4dec-b726-0a23acafdade"
      },
      "outputs": [],
      "source": [
        "# visualize the prediction using diagonal line\n",
        "y = test_predictions #y-axis\n",
        "x = y_test #x-axis\n",
        "fig, ax = plt.subplots(figsize=(10,6)) # create figure\n",
        "ax.scatter(x,y) #scatter plots for x,y\n",
        "ax.set(xlim=(0,55), ylim=(0, 55)) #set limit\n",
        "ax.plot(ax.get_xlim(), ax.get_ylim(), color ='red') # draw 45 degree diagonal in figure\n",
        "plt.xlabel('True Values')\n",
        "plt.ylabel('Predicted values')\n",
        "plt.title('Evaluation Result')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5wOpuX0I4P4"
      },
      "source": [
        "Show the accuracy of Linear Regression on the dataset. The linear regression graph is created by train data and the model line is shown by the blue line which is created using test data and predicted data as we can see most of the red dots are on the line, thus we can say that model has produced the best-fit line."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "Wj4mwhHlBRL1",
        "outputId": "c82c3ff0-4bc6-4a82-c869-5e2f3aaaf78a"
      },
      "outputs": [],
      "source": [
        "#Accuracy of linear regression on the dataset\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.regplot(x=y_test,y=test_predictions,scatter_kws={'color':'red'})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aehFxs9fuXe"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5UPnfGmdIK_"
      },
      "source": [
        "Step 6 - Predict on the Test Data and Compute Evaluation Metrics\n",
        "The first line of code predicts on the train data, while the second line prints the RMSE value on the train data. The same is repeated in the third and fourth lines of code which predicts and prints the RMSE value on test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7m2LWkrcE20",
        "outputId": "ba3a55c6-3d5d-4120-ac7d-cb62554ab790"
      },
      "outputs": [],
      "source": [
        "pred_train= model.predict(X_train)\n",
        "print(np.sqrt(mean_squared_error(y_train,pred_train)))\n",
        "\n",
        "pred= model.predict(X_test)\n",
        "print(np.sqrt(mean_squared_error(y_test,pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAxJHqm8dqDP"
      },
      "source": [
        "Evaluation of the Model Performance\n",
        "The output above shows that the RMSE, which is our evaluation metric, was 3.784 thousand for train data and 3.750 thousand for test data. Ideally, the lower the RMSE value, the better the model performance. However, in contrast to accuracy, it is not straightforward to interpret RMSE as we would have to look at the unit which in our case is in thousands."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3v8MWIMgWge"
      },
      "source": [
        "## Regression Evaluation Metrics\n",
        "\n",
        "\n",
        "Here are three common evaluation metrics for regression problems:\n",
        "\n",
        "**Mean Absolute Error** (MAE) is the mean of the absolute value of the errors:\n",
        "\n",
        "$$\\frac 1n\\sum_{i=1}^n|y_i-\\hat{y}_i|$$\n",
        "\n",
        "**Mean Squared Error** (MSE) is the mean of the squared errors:\n",
        "\n",
        "$$\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2$$\n",
        "\n",
        "**Root Mean Squared Error** (RMSE) is the square root of the mean of the squared errors:\n",
        "\n",
        "$$\\sqrt{\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2}$$\n",
        "\n",
        "Comparing these metrics:\n",
        "\n",
        "- **MAE** is the easiest to understand, because it's the average error.\n",
        "- **MSE** is more popular than MAE, because MSE \"punishes\" larger errors, which tends to be useful in the real world.\n",
        "- **RMSE** is even more popular than MSE, because RMSE is interpretable in the \"y\" units.\n",
        "\n",
        "All of these are **loss functions**, because you want to minimize them."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "environment": {
      "kernel": "python3",
      "name": "tf2-gpu.2-6.m87",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m87"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
